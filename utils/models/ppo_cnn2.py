import torch as th
import torch.nn as nn
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor

class Custom1DCNN(BaseFeaturesExtractor):
    """
    Sequence Length 1000ì— ìµœì í™”ëœ 1D CNN
    """
    def __init__(self, observation_space, features_dim=256):
        super().__init__(observation_space, features_dim)
        
        n_input_channels = observation_space.shape[1] 
        
        self.cnn = nn.Sequential(
            # Layer 1 (1000 -> 500)
            nn.Conv1d(n_input_channels, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2), 
            
            # Layer 2 (500 -> 250)
            nn.Conv1d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2), 
            
            # Layer 3 (250 -> 125)
            nn.Conv1d(64, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2), 

            # ğŸŸ¢ [ì¶”ê°€ë¨] Layer 4 (125 -> 62) : 1000ê°œë‹ˆê¹Œ í•œ ë²ˆ ë” ì••ì¶•!
            nn.Conv1d(64, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2),
            
            nn.Flatten(),
        )

        # (ì´í•˜ ë™ì¼) ì°¨ì› ê³„ì‚° ë¡œì§ì´ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë‘ì‹œë©´ ë©ë‹ˆë‹¤.
        with th.no_grad():
            sample = th.as_tensor(observation_space.sample()[None]).float()
            sample = sample.permute(0, 2, 1)
            n_flatten = self.cnn(sample).shape[1]

        self.linear = nn.Sequential(
            nn.Linear(n_flatten, features_dim),
            nn.ReLU()
        )
    
    # forward í•¨ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ
    def forward(self, observations: th.Tensor) -> th.Tensor:
        x = observations.permute(0, 2, 1)
        x = self.cnn(x)
        return self.linear(x)